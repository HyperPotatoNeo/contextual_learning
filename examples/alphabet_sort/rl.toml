
max_steps = 200
seq_len = 4096

[ckpt] # Checkpoint at the end of training

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[wandb]
project = "alphabet-sort"
name = "alphabet-sort"

[trainer.model]
impl = "liger_kernel"

[trainer.model.ac]
freq = 1

[trainer.model.lora]
rank = 32
alpha = 64

[trainer.optim]
lr = 1e-5

[orchestrator]
batch_size = 512
rollouts_per_example = 8

[orchestrator.sampling]
max_tokens = 4096

[[orchestrator.env]]
id = "rg-sokoban-env"
args = { dataset_name = "sokoban", size = 2000, seed = 0, prompt_prefix = "Solve the puzzle and reason carefully.", prompt_suffix = "Final answer should be in <answer></answer> tags in the required format." }

[inference] # Default inference config